library(moderndive)
library(readr)
ggplot(data = hate_crimes, aes(x = trump_support, y = hate_crimes)) +
geom_boxplot() +
labs(x = "Voter Support of Trump",
y = "Number of Hate Crimes per 100K people",
title = "Hate Crimes in relation to Trump Support")
ggplot(data = hate_crimes, aes(x = urbanization, y = hate_crimes)) +
geom_boxplot() +
labs(x = "Urbanization",
y = "Number of Hate Crimes per 100K people",
title = "Hate Crimes in relation to Urbanization") +
theme_classic()
ggplot(data = hate_crimes, aes(x = urbanization, y = hate_crimes_ps)) +
geom_boxplot() +
labs(x = "Urbanization",
y = "Number of Hate Crimes per 100K people",
title = "Hate Crimes in relation to Urbanization") +
theme_classic()
View(hate_crimes_ps)
ggplot(data = hate_crimes_ps, aes(x = urbanization, y = hate_crimes)) +
geom_boxplot() +
labs(x = "Urbanization",
y = "Number of Hate Crimes per 100K people",
title = "Hate Crimes in relation to Urbanization") +
theme_classic()
hate_mod <- lm(hate_crimes ~ urbanization, data = hate_crimes_ps)
get_regression_table(hate_mod)
y_hat = 0.352 - 0.098 * 1
y_hat
library(ggplot2)
library(dplyr)
library(moderndive)
library(readr)
ggplot(data = hate_crimes, aes(x = urbanization, y = income)) +
geom_boxplot(fill = c("sienna", "darkgreen")) +
labs(x = "Level of urbanization in a state", y = "Median household income in USD $",
title = "Household income across an urbanization gradient in 2016") +
theme_classic()
library(ggplot2)
library(dplyr)
library(moderndive)
library(readr)
summary(hate_crimes)
hate_crimes_ps4 <- hate_crimes %>%
select(state, hs, income, urbanization) %>%
na.omit()
hate_crimes_ps4 <- hate_crimes %>%
select(state, hs, income, urbanization) %>%
na.omit()
ggplot(data = hate_crimes_ps4, aes(x = urbanization, y = income)) +
geom_boxplot(fill = c("sienna", "darkgreen")) +
labs(x = "Level of urbanization in a state", y = "Median household income in USD $",
title = "Household income across an urbanization gradient in 2016") +
theme_classic()
ggplot(data = hate_crimes_ps4, aes(y = income, x = hs, color = urbanization)) +
geom_point()+
geom_parallel_slopes(se = FALSE) +
labs(x = "Percent of adults with high-school degree",
y = "Median household income in USD $",
title = "Education and income in states with differing levels of urbanization"
) +
theme_classic()
ggplot(data = hate_crimes_ps4, aes(y = income, x = hs, color = urbanization)) +
geom_point()+
geom_smooth(method = "lm", se = FALSE) +
labs(
x = "Percent of adults with high-school degree",
y = "Median household income in USD $",
title = "Education and income in states with differing levels of urbanization") +
theme
ggplot(data = hate_crimes_ps4, aes(y = income, x = hs, color = urbanization)) +
geom_point()+
geom_smooth(method = "lm", se = FALSE) +
labs(
x = "Percent of adults with high-school degree",
y = "Median household income in USD $",
title = "Education and income in states with differing levels of urbanization") +
theme_classic()
income_parallel_model <- lm(income ~ hs + urbanization, data = hate_crimes)
income_interaction_model <- lm(income ~ hs * urbanization, data = hate_crimes)
get_regression_summaries(income_parallel_model)
get_regression_summaries(income_interaction_model)
ggplot(data = hate_crimes_ps4, aes(y = income, x = hs, color = urbanization)) +
geom_point()+
geom_smooth(method = "lm", se = FALSE) +
labs(
x = "Percent of adults with high-school degree",
y = "Median household income in USD $",
title = "Education and income in states with differing levels of urbanization") +
theme_classic()
get_regression_table(income_parallel_model)
get_regression_table(income_interaction_model)
income_parallel_model <- lm(income ~ hs + urbanization, data = hate_crimes_ps4)
income_interaction_model <- lm(income ~ hs * urbanization, data = hate_crimes_ps4)
get_regression_summaries(income_parallel_model)
get_regression_summaries(income_interaction_model)
get_regression_table(income_parallel_model)
get_regression_table(income_interaction_model)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moderndive)
library(tidyverse)
library(moderndive)
head(tactile_prop_red)
ggplot(tactile_prop_red, aes(x = prop_red)) +
geom_histogram(binwidth = 0.05, boundary = 0.4, color = "white") +
labs(x = "Proportion of 50 balls that were red",
title = "Distribution of 33 proportions red") +
theme_classic()
# Segment 2: sample size = 50 ------------------------------
# 2.a) Virtually use shovel 1000 times
set.seed(107)
virtual_samples_50 <- bowl %>%
rep_sample_n(size = 50, reps = 1000)
# Compute resulting 1000 replicates of proportion red
virtual_prop_red_50 <- virtual_samples_50 %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 50)
#Plot distribution via a histogram
ggplot(virtual_prop_red_50, aes(x = prop_red)) +
geom_histogram(binwidth = 0.05, boundary = 0.4, color = "white") +
labs(x = "Proportion of 50 balls that were red", title = "50")  +
theme_classic()
summary(virtual_prop_red_50)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
set.seed(76)
comparing_n_table <- virtual_prop %>%
group_by(n) %>%
summarize(sd = sd(prop_red)) %>%
mutate(
n = str_c("n = ")
) %>%
rename(`Sample size` = n, `Standard error of $\\widehat{p}$` = sd) %>%
sample_frac(1)
virtual_prop_red_50
bowl %>%
rep_sample_n(size = 50, reps = 10)
bowl %>%
rep_sample_n(size = 50, reps = 10) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 50, n=50)
set.seed(76)
vp50<-bowl %>%
rep_sample_n(size = 50, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 50, n=50)
vp100<-bowl %>%
rep_sample_n(size = 100, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 100, n=100)
vp50<-bowl %>%
rep_sample_n(size = 25, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 25, n=25)
virtual_prop<-rbind(vp25,vp50,vp100)
set.seed(76)
vp50<-bowl %>%
rep_sample_n(size = 50, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 50, n=50)
vp100<-bowl %>%
rep_sample_n(size = 100, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 100, n=100)
vp25<-bowl %>%
rep_sample_n(size = 25, reps = 1000) %>%
group_by(replicate) %>%
summarize(red = sum(color == "red")) %>%
mutate(prop_red = red / 25, n=25)
virtual_prop<-rbind(vp25,vp50,vp100)
comparing_n_table <- virtual_prop %>%
group_by(n) %>%
summarize(sd = sd(prop_red)) %>%
mutate(
n = str_c("n = ")
) %>%
rename(`Sample size` = n, `Standard error of $\\widehat{p}$` = sd) %>%
sample_frac(1)
comparing_n_table %>%
kable(
digits = 3,
caption = "Three standard errors of the sample proportion based on n = 25, 50, 100",
booktabs = TRUE,
escape = FALSE,
linesep = ""
) %>%
kable_styling(
font_size = ifelse(is_latex_output(), 10, 16),
latex_options = c("hold_position")
)
xlim <- c(-6, 6)
p1 <- ggplot(data = data.frame(x = xlim), aes(x)) +
stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = .5)) +
ylab("") +
# scale_y_continuous(breaks = NULL)+
geom_vline(xintercept = 0, linetype = "dotted") +
coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
ggtitle("High precision, high accuracy")
p2 <- ggplot(data = data.frame(x = xlim), aes(x)) +
stat_function(fun = dnorm, n = 101, args = list(mean = 2.5, sd = .5)) +
ylab("") +
# scale_y_continuous(breaks = NULL)+
geom_vline(xintercept = 0, linetype = "dotted") +
coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
ggtitle("High precision, low accuracy")
p3 <- ggplot(data = data.frame(x = xlim), aes(x)) +
stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1.5)) +
ylab("") +
# scale_y_continuous(breaks = NULL)+
geom_vline(xintercept = 0, linetype = "dotted") +
coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
ggtitle("Low precision, high accuracy")
p4 <- ggplot(data = data.frame(x = xlim), aes(x)) +
stat_function(fun = dnorm, n = 101, args = list(mean = 2.5, sd = 1.5)) +
ylab("") +
# scale_y_continuous(breaks = NULL)+
geom_vline(xintercept = 0, linetype = "dotted") +
coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
ggtitle("Low precision, low accuracy")
library(patchwork)
(p1 | p2) / (p3 | p4)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
set.seed(316)
runif(4,5,6)
set.seed(316)
round(runif(4,5,6),2)
set.seed(316)
time<-round(runif(4,5,6),2)
set.seed(316)
(time<-round(runif(4,5,6),2))
mean(time)
?replicate
replicate(2,mean(round(runif(4,5,6),2)))
set.seed(316)
(time<-round(runif(4,5,6),2))
replicate(2,mean(round(runif(4,5,6),2)))
set.seed(316)
(time<-round(runif(4,5,6),2))
# Repeat this 1000 times
rep_data<-replicate(1000,mean(round(runif(4,5,6),2)))
summary(rep_data)
set.seed(316)
(time<-round(runif(4,5,6),2))
# Repeat this 1000 times
rep_data<-tibble(ave=replicate(1000,mean(round(runif(4,5,6),2))))
library(tidyverse)
library(tidyverse)
set.seed(316)
(time<-round(runif(4,5,6),2))
# Repeat this 1000 times
rep_data<-tibble(ave=replicate(1000,mean(round(runif(4,5,6),2))))
summary(rep_data)
ggplot(rep_data,aes(x=ave)) +
geom_histogram()
ggplot(rep_data,aes(x=ave)) +
geom_histogram()
xlim(5.1,5.9)
ggplot(rep_data,aes(x=ave)) +
geom_histogram()
ggplot(rep_data,aes(x=ave)) +
geom_histogram() +
xlim(5.1,5.9)
ggplot(rep_data,aes(x=ave)) +
geom_histogram() +
xlim(5.1,5.9)
# Repeat this 1000 times
rep_data2<-tibble(ave=replicate(1000,mean(round(runif(10,5,6),2))))
ggplot(rep_data,aes(x=ave)) +
geom_histogram() +
xlim(5.1,5.9) +
theme_classic()
ggplot(rep_data2,aes(x=ave)) +
geom_histogram() +
xlim(5.1,5.9) +
theme_classic()
pnorm(3,mu=6,sd=3)
?prnorm
?pnorm
pnorm(3,mean=6,sd=3)
pnorm(12,mean=6,sd=3,lower.tail = FALSE)
pnorm(12,mean=6,sd=3)-pnorm(0,mean=6,sd=3)
qnorm(.025,mean=6,sd=3)
?qnorm
qnorm(.975,mean=6,sd=3)
qnorm(1,mean=6,sd=3)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moderndive)
library(infer)
pennies
pennies_sample
head(pennies_sample)
pennies_sample %>%
summarize(mean_year = mean(year))
ggplot(pennies_sample, aes(x = year)) +
geom_histogram(binwidth = 10, color = "white") +
theme_classic()
head(pennies_resamples)
pennies_resamples %>%
select(replicate==1) %>%
ggplot(aes(x = year)) +
geom_histogram(binwidth = 10, color = "white") +
theme_classic()
pennies_resamples %>%
filter(replicate==1) %>%
ggplot(aes(x = year)) +
geom_histogram(binwidth = 10, color = "white") +
theme_classic()
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year)) %>%
ggplot(aes(x = mean_year)) +
geom_histogram(binwidth = 10, color = "white") +
theme_classic()
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year)) %>%
ggplot(aes(x = mean_year)) +
geom_histogram(binwidth = 10, color = "white") +
theme_classic()
resampled_means <- pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year)) %>%
ggplot(aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
theme_classic()
pennies_resamples %>%
group_by(name) %>%
summarize(mean_year = mean(year)) %>%
ggplot(aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
theme_classic()
head(pennies_sample)
#Set a seed for reproducibility of results.
set.seed(84337)
# Samples of size 50 repeated 1000 times
virtual_resampled_means <- pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>%
group_by(replicate) %>%
summarize(mean_year = mean(year))
head(virtual_resampled_means)
# An estiamte of the population mean would be the mean of the bootstrap distribution
virtual_resampled_means %>%
summarize(mean_of_means = mean(mean_year))
# The bootstrap distribution
ggplot(virtual_resampled_means, aes(x = mean_year)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
labs(x = "sample mean") +
theme_classic()
virtual_resampled_means %>%
summarize(mean_of_means = mean(mean_year))
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
qnorm(.68+32/2)
qnorm(.68+.32/2)
library(tidyverse)
library(moderndive)
head(pennies_sample)
set.seed(52249)
pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 10)
set.seed(52249)
pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 10) %>%
group_by(replicate) %>%
summarize(mean=mean(year))
set.seed(52249)
bootstrap_dist<-pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 10) %>%
group_by(replicate) %>%
summarize(mean=mean(year))
set.seed(52249)
bootstrap_dist<-pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 10) %>%
group_by(replicate) %>%
summarize(ave=mean(year))
bootstrap_dist %>%
ggplot(aes(x=ave)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990, fill = "cyan") +
theme_classic()
set.seed(52249)
bootstrap_dist<-pennies_sample %>%
rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>%
group_by(replicate) %>%
summarize(ave=mean(year))
bootstrap_dist %>%
ggplot(aes(x=ave)) +
geom_histogram(binwidth = 1, color = "white", boundary = 1990, fill = "cyan") +
theme_classic()
bootstrap_dist %>%
ggplot(aes(x=ave)) +
geom_histogram(binwidth = 1, color = "black", boundary = 1990, fill = "cyan") +
theme_classic()
?quantile
quantile(bootstrap_dist,probs=c(2.5,97.5))
quantile(bootstrap_dist,probs=c(0.25,.975))
quantile(bootstrap_dist$ave,probs=c(0.25,.975))
bootstrap_dist %>%
summarize(lower=quantile(ave,probs=0.25),upper=qunatile=ave,probs=.975))
bootstrap_dist %>%
summarize(lower=quantile(ave,probs=0.25),upper=quantile(ave,probs=.975))
bootstrap_dist %>%
summarize(center=mean(ave),lower=center-sd(ave)*qnorn(.975))
bootstrap_dist %>%
summarize(center=mean(ave),lower=center-sd(ave)*qnorm(.975))
bootstrap_dist %>%
summarize(center=mean(ave),lower=center-sd(ave)*qnorm(.975),upper=center+sd(ave)*qnorm(.975))
bootstrap_dist %>%
summarize(center=mean(ave),
lower=quantile(ave,probs=0.25),
upper=quantile(ave,probs=.975))
bootstrap_dist %>%
summarize(center=mean(ave),
lower=center-sd(ave)*qnorm(.975),
upper=center+sd(ave)*qnorm(.975))
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moderndive)
library(infer)
?specify
pennies_sample %>%
specify(year~)
pennies_sample %>%
specify(year)
pennies_sample %>%
specify(formula=year~)
pennies_sample %>%
specify(response=year)
pennies_sample %>%
specify(response=year) %>%
head()
pennies_sample %>%
specify(formula=year~NULL) %>%
head()
pennies_sample %>%
specify(formula=year~NULL) %>%
generate(reps = 1000, type = "bootstrap") %>%
head()
pennies_sample %>%
specify(formula=year~NULL) %>%
generate(reps = 1000) %>%
calculate(stat = "mean") %>%
head()
boot_dist_mean <- pennies_sample %>%
specify(formula=year~NULL) %>%
generate(reps = 1000) %>%
calculate(stat = "mean")
boot_dist_mean <- pennies_sample %>%
specify(formula=year~NULL) %>%
generate(reps = 1000, type = "bootstrap") %>%
calculate(stat = "mean")
# Visualize the results
visualize(boot_dist_mean)
# Visualize the results
visualize(boot_dist_mean) +
shade_confidence_interval(endpoints = percentile_ci)
?shade_confidence_interval
(percentile_ci <- boot_dist_mean %>%
get_confidence_interval(level = 0.95, type = "percentile"))
# Visualize the results
visualize(boot_dist_mean) +
shade_confidence_interval(endpoints = percentile_ci)
(standard_error_ci <- boot_dist_mean %>%
get_confidence_interval(type = "se", point_estimate = mean(pennies_sample)))
mean(pennies_sample)
mean_pennies <- pennies_sample %>%
summarize(year)
(mean_pennies <- pennies_sample %>%
summarize(year))
(mean_pennies <- pennies_sample %>%
summarize(ave=mean(year)))
(mean_pennies <- pennies_sample %>%
summarize(ave=mean(year)) %>%
pull())
(standard_error_ci <- boot_dist_mean %>%
get_confidence_interval(type = "se", point_estimate = mean_pennies))
set.seed(539)
bootstrap_distribution <- pennies_sample %>%
specify(formula = year ~ NULL) %>%
generate(reps = 1000) %>%
calculate(stat = "median")
set.seed(539)
bootstrap_distribution <- pennies_sample %>%
specify(formula = year ~ NULL) %>%
generate(reps = 1000, type="bootstrap") %>%
calculate(stat = "median")
percentile_ci <- bootstrap_distribution %>%
get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
visualize(bootstrap_distribution)
visualize(bootstrap_distribution) +
shade_confidence_interval(endpoints = percentile_ci) +
theme_classic()
