---
title: "Math 300 Lesson 20 Notes"
subtitle: "Sampling Framework"
author: "YOUR NAME HERE"
date: "`r format(Sys.time(), '%B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: lumen
    toc: yes
    toc_float: yes
    css: NTI.css
---


```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives

1. Know and correctly use the terminology and notation for the sampling concepts such as population, census, point estimate, biased, etc. 

2. Explain the impact of sample size on the sample distribution and number of replications on the sampling procedure.  

3. Use and explain the terms accuracy and precision in the context of sampling. 

## Reading 

[Chapter 7.3](https://moderndive.com/7-sampling.html#sampling-framework)

## Lesson 

Work through the learning checks LC7.8 - 7.20. Complete the code as necessary.

+ This line from the book is a good summary:

What you have been performing is statistical inference. This is one of the most important concepts in all of statistics. So much so, we included this term in the title of our book: “Statistical Inference via Data Science”. More generally speaking,

-- If the sampling of a sample of size *n*  is done at random, then
-- the sample is unbiased and representative of the population of size *N*, thus
-- any result based on the sample can generalize to the population, thus
-- the point estimate is a “good guess” of the unknown population parameter, thus
-- instead of performing a census, we can infer about the population using sampling.

+ Try to use the terminology and notation as much as possible from this point on. You can use the bin or red and white balls as an example to go back to. 

+ Standard error and standard deviation can get confused. The standard error is simply the standard deviation of the point estimate. 

### Setup

*Code to setup the learning checks. Complete the code and remove extra comment symbols.*

```{r message=FALSE}
library(tidyverse)
library(moderndive)
``` 

```{r}
# Segment 2: sample size = 50 ------------------------------
# Virtually use shovel 1000 times
#set.seed(107)
# virtual_samples_50 <- bowl %>% 
#  rep_sample_n(size = ____________, reps = 1000)
```


```{r}
# Compute resulting 1000 replicates of proportion red
# virtual_prop_red_50 <- virtual_samples_50 %>% 
#   group_by(_______________) %>% 
#   summarize(red = sum(color == "______________")) %>% 
#   mutate(prop_red = ___________ / 50)
```

```{r}
#summary(virtual_prop_red_50)
```


```{r}
#Plot distribution via a histogram
# ggplot(virtual_prop_red_50, aes(x = ________)) +
#   geom_histogram(binwidth = 0.05, boundary = 0.4, color = "white") +
#   labs(x = "Proportion of 50 balls that were red", title = "50")  +
#   theme_classic()
```

### LC 7.8 (Objective 1)

**(LC 7.8)** In the case of our bowl activity, what is the *population parameter*? Do we know its value?
  
  **Solution**: 
  
 

### LC 7.9 (Objective 1)

**(LC 7.9)** What would performing a census in our bowl activity correspond to? Why did we not perform a census?
  
  **Solution**: 
  

### LC 7.10 (Objective 1)

**(LC 7.10)** What purpose do *point estimates* serve in general? What is the name of the point estimate specific to our bowl activity? What is its mathematical notation?
  
  **Solution**: 
  


### LC 7.11 (Objective 1)

**(LC 7.11)** How did we ensure that our tactile samples using the shovel were random?

**Solution**: 



### LC 7.12 (Objective 1)

**(LC 7.12)** Why is it important that sampling be done *at random*?

**Solution**: 




### LC 7.13 (Objective )

**(LC 7.13)** What are we *inferring* about the bowl based on the samples using the shovel?

**Solution**: 



### LC 7.14 (Objective )

**(LC 7.14)** What purpose did the *sampling distributions* serve?

**Solution**: 

  

### LC 7.15 (Objective 1)

**(LC 7.15)** What does the *standard error* of the sample proportion $\widehat{p}$ quantify? 

**Solution**: 



### LC 7.16 (Objective 2)

**(LC 7.16)** The table that follows is a version of Table 7.3 matching sample sizes $n$ to different *standard errors* of the sample proportion $\widehat{p}$, but with the rows randomly re-ordered and the sample sizes removed. Fill in the table by matching the correct sample sizes to the correct standard errors. Simply list the order of sample size in your answer. 

```{r comparing-n-3-solution, eval=TRUE, echo=FALSE}
set.seed(76)
vp50<-bowl %>% 
  rep_sample_n(size = 50, reps = 1000) %>%
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 50, n=50)
vp100<-bowl %>% 
  rep_sample_n(size = 100, reps = 1000) %>%
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 100, n=100)
vp25<-bowl %>% 
  rep_sample_n(size = 25, reps = 1000) %>%
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 25, n=25)
virtual_prop<-rbind(vp25,vp50,vp100)
```


```{r eval=TRUE, echo=FALSE}
comparing_n_table <- virtual_prop %>%
  group_by(n) %>%
  summarize(sd = sd(prop_red)) %>%
  mutate(
    n = str_c("n = ")
  ) %>%
  rename(`Sample size` = n, `Standard error of $\\widehat{p}$` = sd) %>%
  sample_frac(1)

comparing_n_table %>%
  kable(
    digits = 3,
    caption = "Three standard errors of the sample proportion based on n = 25, 50, 100",
    booktabs = TRUE,
    escape = FALSE,
    linesep = ""
  ) %>%
  kable_styling(
    font_size = ifelse(is_latex_output(), 10, 16),
    latex_options = c("hold_position")
  )
```

**Solution**:

 
***

For the following four learning checks, let the *estimate* be the sample proportion $\widehat{p}$: the proportion of a shovel's balls that were red. It estimates the population proportion $p$: the proportion of the bowl's balls that were red.

### LC 7.17 (Objective 3)

**(LC 7.17)** What is the difference between an *accurate* estimate and a *precise* estimate? 

**Solution**:



### LC 7.18 (Objective 3)

**(LC 7.18)** How do we ensure that an estimate is *accurate*? How do we ensure that an estimate is *precise*?

**Solution**:



### LC 7.19 (Objective 1)

**(LC 7.19)** In a real-life situation, we would not take 1000 different samples to infer about a population, but rather only one. Then, what was the purpose of our exercises where we took 1000 different samples?

**Solution**:



### LC 7.20 (Objective 3)

**(LC 7.20)** Figure 7.13 with the targets shows four combinations of "accurate versus precise" estimates. Draw four corresponding *sampling distributions* of the sample proportion $\widehat{p}$, like the one in the left-most plot in Figure 7-12. Complete the code.

**Solution**:



```{r, echo=FALSE}
 xlim <- c(-6, 6)
 p1 <- ggplot(data = data.frame(x = xlim), aes(x)) +
   stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = .5)) +
   ylab("") +
   # scale_y_continuous(breaks = NULL)+
   geom_vline(xintercept = 0, linetype = "dotted") +
   coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
   ggtitle("High precision, high accuracy")

# p2 <- ggplot(data = data.frame(x = xlim), aes(x)) +
#   stat_function(fun = dnorm, n = 101, args = list(mean = _________, sd = .5)) +
#   ylab("") +
#   # scale_y_continuous(breaks = NULL)+
#   geom_vline(xintercept = 0, linetype = "dotted") +
#   coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
#   ggtitle("High precision, low accuracy")
#
# p3 <- ggplot(data = data.frame(x = xlim), aes(x)) +
#   stat_function(fun = dnorm, n = 101, args = list(mean = _________, sd = 1.5)) +
#   ylab("") +
#   # scale_y_continuous(breaks = NULL)+
#   geom_vline(xintercept = 0, linetype = "dotted") +
#   coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
#   ggtitle("Low precision, high accuracy")
# 
# p4 <- ggplot(data = data.frame(x = xlim), aes(x)) +
#   stat_function(fun = dnorm, n = 101, args = list(mean = _________, sd = 1.5)) +
#   ylab("") +
#   # scale_y_continuous(breaks = NULL)+
#   geom_vline(xintercept = 0, linetype = "dotted") +
#   coord_cartesian(xlim = xlim, ylim = c(0, 0.8)) +
#   ggtitle("Low precision, low accuracy")
#
#library(patchwork)
#(p1 | p2) / (p3 | p4)
```





## Documenting software 

  * File creation date: `r Sys.Date()`
  * `r R.version.string`
  * `tidyverse` package version: `r packageVersion("tidyverse")`
  * `moderndive` package version: `r packageVersion("moderndive")`
